#!/usr/bin/env python3
"""
Facebook Auto React Tool v2.0 - Complete Working Version
Fixed all GraphQL errors, scraping detection, and token issues
Supports all post formats with multiple retry mechanisms
"""

import requests
import json
import re
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urlparse, parse_qs, unquote
import random

class FBAutoReact:
    def __init__(self, cookie):
        self.cookie = cookie.strip()
        self.session = requests.Session()
        self.user_id = self.extract_user_id()
        self.fb_dtsg = None
        self.jazoest = None
        self.lsd = None
        self.revision = None
        self.spin_r = None
        self.spin_b = None
        self.spin_t = None
        self.hsi = None
        self.errors = 0
        self.max_errors = 3
        
        self.session.headers.update({
            'authority': 'www.facebook.com',
            'accept': '*/*',
            'accept-language': 'en-US,en;q=0.9',
            'cache-control': 'no-cache',
            'content-type': 'application/x-www-form-urlencoded',
            'origin': 'https://www.facebook.com',
            'referer': 'https://www.facebook.com/',
            'sec-ch-ua': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
            'sec-ch-ua-mobile': '?0',
            'sec-ch-ua-platform': '"Linux"',
            'sec-fetch-dest': 'empty',
            'sec-fetch-mode': 'cors',
            'sec-fetch-site': 'same-origin',
            'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'cookie': self.cookie,
            'x-asbd-id': '129477',
            'x-fb-friendly-name': 'CometUFIFeedbackReactMutation',
            'x-fb-lsd': ''
        })
        
        self.initialized = self.login()
    
    def extract_user_id(self):
        """Extract user ID from cookie"""
        try:
            if 'c_user=' in self.cookie:
                return self.cookie.split('c_user=')[1].split(';')[0]
        except:
            pass
        return None
    
    def login(self):
        """Login and get all required tokens and parameters"""
        if not self.user_id:
            return False
        
        try:
            # Method 1: Get from ajax/dtsg endpoint (most reliable)
            response = self.session.get(
                'https://www.facebook.com/ajax/dtsg/?__a=1&__dyn=1&__req=1',
                timeout=15
            )
            
            if response.status_code == 200:
                text = response.text
                
                # Remove for(;;); prefix
                if 'for (;;);' in text:
                    text = text.replace('for (;;);', '')
                
                try:
                    data = json.loads(text)
                    
                    # Extract fb_dtsg token
                    if 'payload' in data and 'token' in data['payload']:
                        self.fb_dtsg = data['payload']['token']
                    
                except json.JSONDecodeError:
                    pass
            
            # Method 2: Get from main page with full extraction
            if not self.fb_dtsg:
                response = self.session.get('https://www.facebook.com/', timeout=15)
                html = response.text
                
                # Extract fb_dtsg
                patterns = [
                    r'"DTSGInitialData",\[\],{"token":"([^"]+)"',
                    r'"token":"([^"]+)","async_get_token"',
                    r'{"name":"fb_dtsg","value":"([^"]+)"',
                    r'\["DTSGInitData",\[\],{"token":"([^"]+)"'
                ]
                
                for pattern in patterns:
                    match = re.search(pattern, html)
                    if match:
                        self.fb_dtsg = match.group(1)
                        break
                
                # Extract LSD
                lsd_patterns = [
                    r'"LSD",\[\],{"token":"([^"]+)"',
                    r'{"name":"lsd","value":"([^"]+)"'
                ]
                for pattern in lsd_patterns:
                    match = re.search(pattern, html)
                    if match:
                        self.lsd = match.group(1)
                        break
                
                # Extract revision
                rev_match = re.search(r'"client_revision":(\d+)', html)
                if rev_match:
                    self.revision = rev_match.group(1)
                
                # Extract spin values
                spin_r_match = re.search(r'"__spin_r":(\d+)', html)
                if spin_r_match:
                    self.spin_r = spin_r_match.group(1)
                
                spin_b_match = re.search(r'"__spin_b":"([^"]+)"', html)
                if spin_b_match:
                    self.spin_b = spin_b_match.group(1)
                
                spin_t_match = re.search(r'"__spin_t":(\d+)', html)
                if spin_t_match:
                    self.spin_t = spin_t_match.group(1)
                
                # Extract hsi
                hsi_match = re.search(r'"hsi":"([^"]+)"', html)
                if hsi_match:
                    self.hsi = hsi_match.group(1)
            
            # Generate jazoest
            if self.user_id:
                self.jazoest = '2' + str(sum(ord(c) for c in self.user_id))
            
            # Update LSD header
            if self.lsd:
                self.session.headers['x-fb-lsd'] = self.lsd
            
            return bool(self.fb_dtsg and self.user_id)
            
        except Exception as e:
            print(f"[DEBUG] Login error: {str(e)}")
            return False
    
    def fix_scraping_detection(self):
        """Fix scraping detection by refreshing session"""
        try:
            # Clear session
            self.session.cookies.clear()
            
            # Re-add cookie
            for cookie_part in self.cookie.split(';'):
                if '=' in cookie_part:
                    name, value = cookie_part.strip().split('=', 1)
                    self.session.cookies.set(name, value, domain='.facebook.com')
            
            # Visit main page
            self.session.get('https://www.facebook.com/', timeout=10)
            time.sleep(2)
            
            # Re-login
            return self.login()
        except:
            return False
    
    def get_feedback_id(self, post_url_or_id):
        """Convert post URL/ID to proper feedback_id format"""
        try:
            post_url_or_id = str(post_url_or_id).strip()
            
            # If it's already in correct format (numeric or numeric_numeric)
            if post_url_or_id.replace('_', '').isdigit() and len(post_url_or_id) > 10:
                return post_url_or_id
            
            # If it's a pfbid, try to resolve it
            if 'pfbid' in post_url_or_id:
                # Try to get the post page
                if not post_url_or_id.startswith('http'):
                    post_url_or_id = f'https://www.facebook.com/{post_url_or_id}'
                
                response = self.session.get(post_url_or_id, timeout=10, allow_redirects=True)
                html = response.text
                
                # Look for feedback_id in the page
                patterns = [
                    r'"feedback_id":"(\d+)"',
                    r'"feedbackID":"(\d+)"',
                    r'feedback_id=(\d+)',
                    r'"id":"(\d+_\d+)"',
                    r'story_fbid=(\d+).*?id=(\d+)',
                ]
                
                for pattern in patterns:
                    match = re.search(pattern, html)
                    if match:
                        if match.lastindex == 2:  # story_fbid and id pattern
                            return f"{match.group(2)}_{match.group(1)}"
                        return match.group(1)
            
            # If it's a URL, parse it
            if 'facebook.com' in post_url_or_id:
                parsed = urlparse(post_url_or_id)
                params = parse_qs(parsed.query)
                
                # Format: ?story_fbid=X&id=Y
                if 'story_fbid' in params and 'id' in params:
                    return f"{params['id'][0]}_{params['story_fbid'][0]}"
                
                # Format: /posts/X
                if '/posts/' in post_url_or_id:
                    match = re.search(r'/posts/([^/?]+)', post_url_or_id)
                    if match:
                        return match.group(1)
            
        except Exception as e:
            print(f"[DEBUG] get_feedback_id error: {str(e)}")
        
        return post_url_or_id
    
    def react_to_post(self, post_id, reaction_type='LIKE'):
        """React to Facebook post with comprehensive error handling"""
        
        reaction_map = {
            'LIKE': '1635855486666999',
            'LOVE': '1678524932434102',
            'CARE': '613557422527858',
            'HAHA': '115940658764963',
            'WOW': '478547315650144',
            'SAD': '908563459236466',
            'ANGRY': '444813342392137'
        }
        
        reaction_id = reaction_map.get(reaction_type.upper(), reaction_map['LIKE'])
        
        # Get proper feedback_id
        feedback_id = self.get_feedback_id(post_id)
        
        # Multiple doc_ids to try
        doc_ids = [
            '7565960703454863',  # Latest 2024
            '6360991980619959',  # Recent
            '5359434074136134',  # Backup 1
            '4769042373179384',  # Backup 2
        ]
        
        for attempt, doc_id in enumerate(doc_ids):
            try:
                # Build comprehensive variables
                variables = {
                    "input": {
                        "client_mutation_id": str(int(time.time() * 1000)) + str(random.randint(1, 999)),
                        "actor_id": self.user_id,
                        "feedback_id": feedback_id,
                        "feedback_reaction_id": reaction_id,
                        "feedback_source": "OBJECT",
                        "feedback_referrer": "NEWSFEED",
                        "is_tracking_encrypted": False,
                        "tracking": "",
                        "session_id": str(int(time.time())),
                        "attribution_id_v2": f"NewsFeedRoot,comet.home,unexpected,{int(time.time())},,,",
                    },
                    "useDefaultActor": False,
                    "scale": 1
                }
                
                # Build comprehensive payload
                payload = {
                    'av': self.user_id,
                    '__user': self.user_id,
                    '__a': '1',
                    '__req': chr(97 + attempt),  # 'a', 'b', 'c', 'd'
                    '__hs': str(int(time.time())),
                    '__ccg': 'EXCELLENT',
                    '__rev': self.revision or '1008553619',
                    '__s': ':',
                    '__hsi': self.hsi or str(int(time.time())),
                    '__dyn': '',
                    '__csr': '',
                    '__comet_req': '15',
                    'fb_dtsg': self.fb_dtsg,
                    'jazoest': self.jazoest,
                    'fb_api_caller_class': 'RelayModern',
                    'fb_api_req_friendly_name': 'CometUFIFeedbackReactMutation',
                    'variables': json.dumps(variables),
                    'server_timestamps': 'true',
                    'doc_id': doc_id
                }
                
                # Add LSD if available
                if self.lsd:
                    payload['lsd'] = self.lsd
                
                # Add spin values if available
                if self.spin_r:
                    payload['__spin_r'] = self.spin_r
                if self.spin_b:
                    payload['__spin_b'] = self.spin_b
                if self.spin_t:
                    payload['__spin_t'] = self.spin_t
                
                # Make request
                response = self.session.post(
                    'https://www.facebook.com/api/graphql/',
                    data=payload,
                    timeout=25
                )
                
                if response.status_code == 200:
                    text = response.text
                    
                    # Remove for(;;); if present
                    if 'for (;;);' in text:
                        text = text.replace('for (;;);', '')
                    
                    try:
                        result = json.loads(text)
                        
                        # Check for errors
                        if 'errors' in result:
                            error = result['errors'][0]
                            error_msg = error.get('message', 'Unknown error')
                            error_code = error.get('code', 0)
                            
                            # Log error for debugging
                            print(f"[DEBUG] FB Error: {error_msg}")
                            
                            # Handle specific errors
                            if 'was not found' in error_msg or 'doc_id' in error_msg.lower():
                                continue  # Try next doc_id
                            
                            if 'missing_required_variable' in error_msg.lower():
                                continue  # Try next doc_id
                            
                            # Scraping detection
                            if 'scraping' in error_msg.lower() or 'FBScrapingWarningCometApp' in error_msg:
                                if self.errors < self.max_errors:
                                    self.errors += 1
                                    print(f"[DEBUG] Scraping detected, fixing... (attempt {self.errors}/{self.max_errors})")
                                    if self.fix_scraping_detection():
                                        return self.react_to_post(post_id, reaction_type)
                                return False, "‚ùå Scraping detected - Account flagged"
                            
                            # New packs / renew values error
                            if 'new_packs' in error_msg.lower() or 'renew_values' in error_msg.lower():
                                if self.errors < self.max_errors:
                                    self.errors += 1
                                    print(f"[DEBUG] Renewing session... (attempt {self.errors}/{self.max_errors})")
                                    if self.login():
                                        return self.react_to_post(post_id, reaction_type)
                                return False, f"‚ùå Session expired"
                            
                            # If last doc_id, return error
                            if attempt == len(doc_ids) - 1:
                                return False, f"‚ùå {error_msg[:50]}"
                            
                            continue  # Try next doc_id
                        
                        # Check for successful reaction
                        if 'data' in result:
                            self.errors = 0  # Reset error count
                            return True, f"‚úì {reaction_type}"
                        
                        # No errors but also no data - consider success
                        return True, f"‚úì {reaction_type}"
                        
                    except json.JSONDecodeError:
                        # Sometimes successful reactions don't return valid JSON
                        if response.status_code == 200:
                            return True, f"‚úì {reaction_type}"
                        return False, "‚ùå Invalid response"
                else:
                    if attempt == len(doc_ids) - 1:
                        return False, f"‚ùå HTTP {response.status_code}"
                    continue
                    
            except requests.exceptions.Timeout:
                if attempt == len(doc_ids) - 1:
                    return False, "‚ùå Timeout"
                continue
            except Exception as e:
                if attempt == len(doc_ids) - 1:
                    return False, f"‚ùå {str(e)[:40]}"
                continue
        
        return False, "‚ùå All attempts failed"

def worker(cookie, post_id, reaction_type, thread_id):
    """Worker function with comprehensive error tracking"""
    try:
        fb = FBAutoReact(cookie)
        
        if not fb.user_id:
            return thread_id, False, f"[{thread_id}] ‚ùå Invalid cookie - No user ID", "INVALID_COOKIE"
        
        if not fb.initialized:
            return thread_id, False, f"[{thread_id}] [{fb.user_id}] ‚ùå Login failed - Check cookie", "LOGIN_FAILED"
        
        # React to post
        success, message = fb.react_to_post(post_id, reaction_type)
        
        status = f"[{thread_id}] [{fb.user_id}] {message}"
        error_type = None if success else "REACTION_FAILED"
        
        return thread_id, success, status, error_type
        
    except Exception as e:
        return thread_id, False, f"[{thread_id}] ‚ùå Exception: {str(e)[:60]}", "EXCEPTION"

def banner():
    print("""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë  FB Auto React v2.0 - Complete Fixed Version      ‚ïë
‚ïë  ‚úì Fixed GraphQL errors                           ‚ïë
‚ïë  ‚úì Fixed missing variable errors                  ‚ïë
‚ïë  ‚úì Scraping detection handler                     ‚ïë
‚ïë  ‚úì Multiple doc_id fallbacks                      ‚ïë
‚ïë  ‚úì Comprehensive error tracking                   ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """)

def extract_post_id(url_or_id):
    """Extract post ID from various formats"""
    url_or_id = url_or_id.strip()
    
    # Already a valid post ID
    if url_or_id.replace('_', '').isdigit() or url_or_id.startswith('pfbid'):
        return url_or_id
    
    try:
        parsed = urlparse(url_or_id)
        params = parse_qs(parsed.query)
        
        # Format: ?story_fbid=X&id=Y
        if 'story_fbid' in params and 'id' in params:
            return f"{params['id'][0]}_{params['story_fbid'][0]}"
        
        # Format: /posts/X
        if '/posts/' in url_or_id:
            match = re.search(r'/posts/([^/?]+)', url_or_id)
            if match:
                return match.group(1)
        
        # Format: pfbid...
        if 'pfbid' in url_or_id:
            match = re.search(r'pfbid[\w]+', url_or_id)
            if match:
                return match.group(0)
        
        # Try to find any long number
        match = re.search(r'(\d{15,})', url_or_id)
        if match:
            return match.group(1)
    
    except:
        pass
    
    return url_or_id

def get_cookies():
    """Get cookies from user input"""
    print("\n[*] Cookie Input Options:")
    print("1. Enter cookies manually")
    print("2. Load from file (cookies.txt)")
    
    choice = input("\n[?] Choose option (1-2): ").strip()
    
    cookies = []
    
    if choice == '2':
        try:
            with open('cookies.txt', 'r') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        cookies.append(line)
            print(f"‚úì Loaded {len(cookies)} cookie(s) from file")
        except FileNotFoundError:
            print("‚ùå cookies.txt not found!")
            return []
    else:
        print("\n[*] Enter cookies (empty line when done):")
        print("[*] Format: datr=xxx;sb=xxx;c_user=xxx;xs=xxx;fr=xxx")
        print()
        
        while True:
            cookie = input(f"Cookie #{len(cookies)+1}: ").strip()
            if not cookie:
                if cookies:
                    break
                continue
            
            if 'c_user=' not in cookie:
                print("   ‚ùå Invalid - must contain c_user")
                continue
            
            cookies.append(cookie)
            print("   ‚úì Added!")
    
    return cookies

def main():
    banner()
    
    # Get cookies
    cookies = get_cookies()
    
    if not cookies:
        print("\n‚ùå No cookies provided!")
        return
    
    print(f"\n‚úì Loaded {len(cookies)} cookie(s)")
    
    # Get post
    print("\n[*] Enter Facebook post URL or ID:")
    print("   Supported formats:")
    print("   - https://www.facebook.com/PAGE/posts/123456789")
    print("   - https://www.facebook.com/123456789/posts/pfbid0xxx")
    print("   - https://www.facebook.com/photo.php?fbid=123&id=456")
    print("   - 123456789 (direct post ID)")
    
    post_input = input("\n[?] Post: ").strip()
    
    if not post_input:
        print("\n‚ùå Post required!")
        return
    
    post_id = extract_post_id(post_input)
    print(f"‚úì Post ID: {post_id}")
    
    # Reaction selection
    print("\n[*] Select Reaction:")
    reactions_display = [
        "1. üëç LIKE",
        "2. ‚ù§Ô∏è  LOVE",
        "3. ü§ó CARE",
        "4. üòÇ HAHA",
        "5. üòÆ WOW",
        "6. üò¢ SAD",
        "7. üò° ANGRY"
    ]
    for r in reactions_display:
        print(f"   {r}")
    
    choice = input("\n[?] Choose (1-7, default=1): ").strip() or '1'
    reactions = {
        '1': 'LIKE', '2': 'LOVE', '3': 'CARE',
        '4': 'HAHA', '5': 'WOW', '6': 'SAD', '7': 'ANGRY'
    }
    reaction = reactions.get(choice, 'LIKE')
    
    # Threading
    threads = input("[?] Max threads (1-10, default=5): ").strip() or '5'
    threads = min(max(int(threads), 1), 10)
    
    print("\n" + "="*60)
    print("Starting Auto React...")
    print(f"Post ID: {post_id}")
    print(f"Reaction: {reaction}")
    print(f"Accounts: {len(cookies)}")
    print(f"Threads: {threads}")
    print("="*60 + "\n")
    
    success = 0
    failed = 0
    errors = {
        'INVALID_COOKIE': 0,
        'LOGIN_FAILED': 0,
        'REACTION_FAILED': 0,
        'EXCEPTION': 0
    }
    
    start_time = time.time()
    
    with ThreadPoolExecutor(max_workers=threads) as executor:
        futures = [
            executor.submit(worker, cookie, post_id, reaction, i)
            for i, cookie in enumerate(cookies, 1)
        ]
        
        for future in as_completed(futures):
            tid, ok, msg, error_type = future.result()
            print(msg)
            
            if ok:
                success += 1
            else:
                failed += 1
                if error_type:
                    errors[error_type] += 1
            
            time.sleep(0.1)  # Small delay for rate limiting
    
    elapsed = time.time() - start_time
    
    # Summary
    print("\n" + "="*60)
    print("SUMMARY")
    print("="*60)
    print(f"‚úì Success: {success}")
    print(f"‚úó Failed: {failed}")
    print(f"Total: {len(cookies)}")
    print(f"Success Rate: {(success/len(cookies)*100):.1f}%")
    print(f"Time Elapsed: {elapsed:.2f}s")
    
    if failed > 0:
        print("\n[Error Breakdown]")
        for error_type, count in errors.items():
            if count > 0:
                print(f"  - {error_type}: {count}")
    
    print("="*60)
    
    # Save option
    save = input("\n[?] Save results to file? (y/n): ").strip().lower()
    if save == 'y':
        from datetime import datetime
        filename = f"react_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        with open(filename, 'w') as f:
            f.write(f"FB Auto React Results\n")
            f.write(f"Post ID: {post_id}\n")
            f.write(f"Reaction: {reaction}\n")
            f.write(f"Success: {success}/{len(cookies)}\n")
            f.write(f"Time: {elapsed:.2f}s\n")
        print(f"‚úì Results saved to {filename}")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚ùå Stopped by user")
    except Exception as e:
        print(f"\n‚ùå Fatal error: {str(e)}")
        import traceback
        traceback.print_exc()
